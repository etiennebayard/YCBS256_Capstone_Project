{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled69.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OjAGgXJACdwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "d6db642a-5fe5-4747-9519-b38777bf0b6c"
      },
      "cell_type": "code",
      "source": [
        "# 2019-03-12 Etienne Bayard for Capstone project McGill YCBS256\n",
        "#in Colabs after uploading files 2005_2017datamtleng.csv & 2018datamtleng.csv\n",
        "\n",
        "# Using pandas library for data management\n",
        "import pandas as pd\n",
        "\n",
        "# using numpy for mathematical functions\n",
        "import numpy as np\n",
        "\n",
        "# Read the files into DataFrames: \n",
        "data_train = pd.read_csv('2005_2017datamtleng.csv')\n",
        "data_test = pd.read_csv('2018datamtleng.csv')\n",
        "\n",
        "# View the heads of the DataFrames\n",
        "print(data_train.head())\n",
        "print(data_test.head())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Date  Nombre incidents   Quote  Jour de la semaine  Weekday  \\\n",
            "0  2005-01-01                 4  Medium                   7  Weekend   \n",
            "1  2005-01-02                 1     Low                   1  Weekend   \n",
            "2  2005-01-03                 4  Medium                   2     Week   \n",
            "3  2005-01-04                 8    High                   3     Week   \n",
            "4  2005-01-05                 9    High                   4     Week   \n",
            "\n",
            "   Max Temp (C)  Min Temp (C)  Mean Temp (C)  Heat Deg Days (C)  \\\n",
            "0           6.4         -12.0           -2.8               20.8   \n",
            "1          -5.4         -15.9          -10.7               28.7   \n",
            "2           1.2          -7.1           -3.0               21.0   \n",
            "3          -2.1          -7.1           -4.6               22.6   \n",
            "4          -4.0         -14.3           -9.2               27.2   \n",
            "\n",
            "   Cool Deg Days (C)  Total Precip (mm)  Snow on Grnd (cm)  \n",
            "0                0.0                0.2                  2  \n",
            "1                0.0               11.4                  1  \n",
            "2                0.0                0.0                  5  \n",
            "3                0.0                0.0                  5  \n",
            "4                0.0                0.0                  5  \n",
            "         Date  Nombre incidents   Quote  Jour de la semaine Weekday  \\\n",
            "0  2018-01-01                 4  Medium                   2    Week   \n",
            "1  2018-01-02                 3  Medium                   3    Week   \n",
            "2  2018-01-03                 1     Low                   4    Week   \n",
            "3  2018-01-04                 1     Low                   5    Week   \n",
            "4  2018-01-05                 2     Low                   6    Week   \n",
            "\n",
            "   Max Temp (C)  Min Temp (C)  Mean Temp (C)  Heat Deg Days (C)  \\\n",
            "0         -18.8         -25.3          -22.1               40.1   \n",
            "1         -14.0         -24.9          -19.5               37.5   \n",
            "2         -10.2         -16.2          -13.2               31.2   \n",
            "3          -6.7         -14.1          -10.4               28.4   \n",
            "4         -14.1         -22.5          -18.3               36.3   \n",
            "\n",
            "   Cool Deg Days (C)  Total Precip (mm)  Snow on Grnd (cm)  \n",
            "0                0.0                0.0                 18  \n",
            "1                0.0                2.5                 18  \n",
            "2                0.0                0.2                 22  \n",
            "3                0.0                0.9                 23  \n",
            "4                0.0                3.4                 17  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XVRymB6bFECe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "outputId": "6e552675-8cc1-4bf3-942f-253cc9a2c5de"
      },
      "cell_type": "code",
      "source": [
        "#One hot encode categorical data\n",
        "#http://www.insightsbot.com/blog/zuyVu/python-one-hot-encoding-with-pandas-made-simple\n",
        "df_train_dummies = pd.get_dummies(data_train[['Quote','Weekday']], prefix = 'category')\n",
        "print(data_train[['Quote','Weekday']].head())\n",
        "print(df_train_dummies.head())\n",
        "\n",
        "df_test_dummies = pd.get_dummies(data_test[['Quote','Weekday']], prefix = 'category')\n",
        "print(data_test[['Quote','Weekday']].head())\n",
        "print(df_test_dummies.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Quote  Weekday\n",
            "0  Medium  Weekend\n",
            "1     Low  Weekend\n",
            "2  Medium     Week\n",
            "3    High     Week\n",
            "4    High     Week\n",
            "   category_High  category_Low  category_Medium  category_Week  \\\n",
            "0              0             0                1              0   \n",
            "1              0             1                0              0   \n",
            "2              0             0                1              1   \n",
            "3              1             0                0              1   \n",
            "4              1             0                0              1   \n",
            "\n",
            "   category_Weekend  \n",
            "0                 1  \n",
            "1                 1  \n",
            "2                 0  \n",
            "3                 0  \n",
            "4                 0  \n",
            "    Quote Weekday\n",
            "0  Medium    Week\n",
            "1  Medium    Week\n",
            "2     Low    Week\n",
            "3     Low    Week\n",
            "4     Low    Week\n",
            "   category_High  category_Low  category_Medium  category_Week  \\\n",
            "0              0             0                1              1   \n",
            "1              0             0                1              1   \n",
            "2              0             1                0              1   \n",
            "3              0             1                0              1   \n",
            "4              0             1                0              1   \n",
            "\n",
            "   category_Weekend  \n",
            "0                 0  \n",
            "1                 0  \n",
            "2                 0  \n",
            "3                 0  \n",
            "4                 0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PRIpCFYSFnVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "9aac49b3-10c2-4286-b8db-a9b77f4e7859"
      },
      "cell_type": "code",
      "source": [
        "#Normalize numerical data\n",
        "df_train_num = data_train[['Max Temp (C)', 'Min Temp (C)', 'Mean Temp (C)', 'Heat Deg Days (C)', 'Cool Deg Days (C)', 'Total Precip (mm)', 'Snow on Grnd (cm)']]\n",
        "df_train_norm =(df_train_num-df_train_num.mean())/df_train_num.std()\n",
        "\n",
        "df_test_num = data_test[['Max Temp (C)', 'Min Temp (C)', 'Mean Temp (C)', 'Heat Deg Days (C)', 'Cool Deg Days (C)', 'Total Precip (mm)', 'Snow on Grnd (cm)']]\n",
        "df_test_norm =(df_test_num-df_test_num.mean())/df_test_num.std()\n",
        "\n",
        "print(df_train_norm.head())\n",
        "print(df_test_norm.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Max Temp (C)  Min Temp (C)  Mean Temp (C)  Heat Deg Days (C)  \\\n",
            "0     -0.459736     -1.315876      -0.881876           0.899217   \n",
            "1     -1.417739     -1.657258      -1.554594           1.638827   \n",
            "2     -0.881907     -0.886961      -0.898906           0.917941   \n",
            "3     -1.149823     -0.886961      -1.035153           1.067736   \n",
            "4     -1.304078     -1.517204      -1.426862           1.498394   \n",
            "\n",
            "   Cool Deg Days (C)  Total Precip (mm)  Snow on Grnd (cm)  \n",
            "0          -0.461139          -0.396177          -0.172335  \n",
            "1          -0.461139           1.257476          -0.318179  \n",
            "2          -0.461139          -0.425707           0.265197  \n",
            "3          -0.461139          -0.425707           0.265197  \n",
            "4          -0.461139          -0.425707           0.265197  \n",
            "   Max Temp (C)  Min Temp (C)  Mean Temp (C)  Heat Deg Days (C)  \\\n",
            "0     -2.304671     -2.330328      -2.346575           2.605619   \n",
            "1     -1.939861     -2.297272      -2.138192           2.368666   \n",
            "2     -1.651054     -1.578319      -1.633263           1.794512   \n",
            "3     -1.385047     -1.404778      -1.408850           1.539333   \n",
            "4     -1.947462     -2.098940      -2.042015           2.259304   \n",
            "\n",
            "   Cool Deg Days (C)  Total Precip (mm)  Snow on Grnd (cm)  \n",
            "0          -0.512991          -0.449246           1.635935  \n",
            "1          -0.512991           0.016549           1.635935  \n",
            "2          -0.512991          -0.411982           2.116780  \n",
            "3          -0.512991          -0.281559           2.236991  \n",
            "4          -0.512991           0.184236           1.515723  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kx-jQ7zAF1vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "babb135f-d2c9-4bc3-d1c4-1d7e32e075b6"
      },
      "cell_type": "code",
      "source": [
        "#Rebuild data frames with encoded and normalized data\n",
        "data_train_encoded = pd.concat([df_train_norm, df_train_dummies], axis=1)\n",
        "data_test_encoded = pd.concat([df_test_norm, df_test_dummies], axis=1)\n",
        "\n",
        "# View the head of the DataFrames\n",
        "print(data_train_encoded.head())\n",
        "print(data_test_encoded.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Max Temp (C)  Min Temp (C)  Mean Temp (C)  Heat Deg Days (C)  \\\n",
            "0     -0.459736     -1.315876      -0.881876           0.899217   \n",
            "1     -1.417739     -1.657258      -1.554594           1.638827   \n",
            "2     -0.881907     -0.886961      -0.898906           0.917941   \n",
            "3     -1.149823     -0.886961      -1.035153           1.067736   \n",
            "4     -1.304078     -1.517204      -1.426862           1.498394   \n",
            "\n",
            "   Cool Deg Days (C)  Total Precip (mm)  Snow on Grnd (cm)  category_High  \\\n",
            "0          -0.461139          -0.396177          -0.172335              0   \n",
            "1          -0.461139           1.257476          -0.318179              0   \n",
            "2          -0.461139          -0.425707           0.265197              0   \n",
            "3          -0.461139          -0.425707           0.265197              1   \n",
            "4          -0.461139          -0.425707           0.265197              1   \n",
            "\n",
            "   category_Low  category_Medium  category_Week  category_Weekend  \n",
            "0             0                1              0                 1  \n",
            "1             1                0              0                 1  \n",
            "2             0                1              1                 0  \n",
            "3             0                0              1                 0  \n",
            "4             0                0              1                 0  \n",
            "   Max Temp (C)  Min Temp (C)  Mean Temp (C)  Heat Deg Days (C)  \\\n",
            "0     -2.304671     -2.330328      -2.346575           2.605619   \n",
            "1     -1.939861     -2.297272      -2.138192           2.368666   \n",
            "2     -1.651054     -1.578319      -1.633263           1.794512   \n",
            "3     -1.385047     -1.404778      -1.408850           1.539333   \n",
            "4     -1.947462     -2.098940      -2.042015           2.259304   \n",
            "\n",
            "   Cool Deg Days (C)  Total Precip (mm)  Snow on Grnd (cm)  category_High  \\\n",
            "0          -0.512991          -0.449246           1.635935              0   \n",
            "1          -0.512991           0.016549           1.635935              0   \n",
            "2          -0.512991          -0.411982           2.116780              0   \n",
            "3          -0.512991          -0.281559           2.236991              0   \n",
            "4          -0.512991           0.184236           1.515723              0   \n",
            "\n",
            "   category_Low  category_Medium  category_Week  category_Weekend  \n",
            "0             0                1              1                 0  \n",
            "1             0                1              1                 0  \n",
            "2             1                0              1                 0  \n",
            "3             1                0              1                 0  \n",
            "4             1                0              1                 0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nc8SHjxjGNb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating a matrix X for training, as a subset of the dataframe  that includes only the attributes 'Max Temp (C)', 'Min Temp (C)', 'Mean Temp (C)', 'Heat Deg Days (C)', 'Cool Deg Days (C)', 'Total Precip (mm)', 'Snow on Grnd (cm)', 'category_Week', 'category_Weekend'\n",
        "X_train = data_train_encoded[['Max Temp (C)', 'Min Temp (C)', 'Mean Temp (C)', 'Heat Deg Days (C)', 'Cool Deg Days (C)', 'Total Precip (mm)', 'Snow on Grnd (cm)', 'category_Week', 'category_Weekend']].values\n",
        "\n",
        "# Creating a response variable y for training that is the quote for that day given the weather and day of the week (week or weekend): 'category_High', 'category_Low', 'category_Medium', \n",
        "y_train = data_train_encoded[['category_High', 'category_Low', 'category_Medium']].values\n",
        "\n",
        "# We do the same for the test data\n",
        "X_test = data_test_encoded[['Max Temp (C)', 'Min Temp (C)', 'Mean Temp (C)', 'Heat Deg Days (C)', 'Cool Deg Days (C)', 'Total Precip (mm)', 'Snow on Grnd (cm)', 'category_Week', 'category_Weekend']].values\n",
        "y_test = data_test_encoded[['category_High', 'category_Low', 'category_Medium']].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WlnFqiCDGpg1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We'll do the same thing on multiple classifying methods: train the method on the training data and then predict on the test data and assess performance\n",
        "# No cross validation on the training set will be done given it's too long on Neural Networks\n",
        "\n",
        "# For a quick assesment of prediction performance on the test set, we'll be using the accuracy score and the confusion matrix for further analysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBIwHViJHToS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1ee85615-12ae-4b90-87c7-fdcafbd78d0e"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Method 1: Random Forest\n",
        "\n",
        "# Import the random forest model from the Scikit-learn library and run the algorithm (training)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train,y_train)\n",
        "\n",
        "# We now apply our predictive model on the test data (X_test) and compute the accuracy score\n",
        "y_test_pred = rf.predict(X_test)\n",
        "as_rf = accuracy_score(y_test, y_test_pred)\n",
        "print(as_rf)\n",
        "\n",
        "# To run the confusion we must decode the y_test_pred to compare it to the original 'Quote' column of the 2018 data Frame\n",
        "# https://stackoverflow.com/questions/38334296/reversing-one-hot-encoding-in-pandas\n",
        "# pd.get_dummies(y_test_pred).idxmax(1)\n",
        "# Can't follow this method since the model output is not a Pandas dataframe\n",
        "\n",
        "# We must invert encoding on an array beacuse this is what we get as output from the algorithm.\n",
        "# https://stackoverflow.com/questions/43665041/how-compute-confusion-matrix-for-multiclass-classification-in-scikit?rq=1\n",
        "from numpy import argmax\n",
        "inverted_y_test_pred = [ np.argmax(t) for t in y_test_pred ]\n",
        "inverted_y_test = [ np.argmax(t) for t in y_test ]\n",
        "\n",
        "# print(inverted_y_test_pred)\n",
        "# print(inverted_y_test)\n",
        "\n",
        "# We can recompute the accuracy score on the arrays for consistency.\n",
        "as_inv_rf = accuracy_score(inverted_y_test, inverted_y_test_pred)\n",
        "print(as_inv_rf)\n",
        "\n",
        "# Create the confusion matrix from the invert encoded targets.\n",
        "cm_rf = confusion_matrix(inverted_y_test, inverted_y_test_pred)\n",
        "print(cm_rf)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2735294117647059\n",
            "0.31176470588235294\n",
            "[[14  8 12]\n",
            " [53 14 81]\n",
            " [59 21 78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e5-ywHClJ6jF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1938
        },
        "outputId": "afbe98d1-156a-430f-dcad-edeec3c06340"
      },
      "cell_type": "code",
      "source": [
        "# Method 2: Neural networks\n",
        "\n",
        "# Import, built and train a keras NN classifier model and run it \n",
        "\n",
        "# Import\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Single fully connected hidden layer with the same number of neurons as input attributes (9).\n",
        "# The network uses good practice such as the rectifier activation function for the hidden layer. \n",
        "\n",
        "# Build\n",
        "nn = keras.Sequential()\n",
        "nn.add(layers.Dense(9, activation='relu', input_shape=(9,)))\n",
        "nn.add(layers.Dense(9, activation ='relu'))\n",
        "nn.add(layers.Dense(3, activation='relu'))\n",
        "\n",
        "nn.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train\n",
        "# Fit the model\n",
        "nn.fit(X_train, y_train, batch_size=10, epochs=50)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/50\n",
            "4564/4564 [==============================] - 5s 1ms/step - loss: 2.3381\n",
            "Epoch 2/50\n",
            "4564/4564 [==============================] - 2s 409us/step - loss: 1.0406\n",
            "Epoch 3/50\n",
            "4564/4564 [==============================] - 2s 420us/step - loss: 1.0144\n",
            "Epoch 4/50\n",
            "4564/4564 [==============================] - 2s 419us/step - loss: 0.9982\n",
            "Epoch 5/50\n",
            "4564/4564 [==============================] - 2s 419us/step - loss: 0.9947\n",
            "Epoch 6/50\n",
            "4564/4564 [==============================] - 2s 422us/step - loss: 0.9925\n",
            "Epoch 7/50\n",
            "4564/4564 [==============================] - 2s 428us/step - loss: 0.9907\n",
            "Epoch 8/50\n",
            "4564/4564 [==============================] - 2s 418us/step - loss: 0.9904\n",
            "Epoch 9/50\n",
            "4564/4564 [==============================] - 2s 419us/step - loss: 0.9894\n",
            "Epoch 10/50\n",
            "4564/4564 [==============================] - 2s 428us/step - loss: 0.9889\n",
            "Epoch 11/50\n",
            "4564/4564 [==============================] - 2s 421us/step - loss: 0.9885\n",
            "Epoch 12/50\n",
            "4564/4564 [==============================] - 2s 418us/step - loss: 0.9880\n",
            "Epoch 13/50\n",
            "4564/4564 [==============================] - 2s 423us/step - loss: 0.9874\n",
            "Epoch 14/50\n",
            "4564/4564 [==============================] - 2s 422us/step - loss: 0.9876\n",
            "Epoch 15/50\n",
            "4564/4564 [==============================] - 2s 421us/step - loss: 0.9864\n",
            "Epoch 16/50\n",
            "4564/4564 [==============================] - 2s 422us/step - loss: 0.9869\n",
            "Epoch 17/50\n",
            "4564/4564 [==============================] - 2s 414us/step - loss: 0.9873\n",
            "Epoch 18/50\n",
            "4564/4564 [==============================] - 2s 417us/step - loss: 0.9862\n",
            "Epoch 19/50\n",
            "4564/4564 [==============================] - 2s 410us/step - loss: 0.9858\n",
            "Epoch 20/50\n",
            "4564/4564 [==============================] - 2s 419us/step - loss: 0.9872\n",
            "Epoch 21/50\n",
            "4564/4564 [==============================] - 2s 418us/step - loss: 0.9859\n",
            "Epoch 22/50\n",
            "4564/4564 [==============================] - 2s 421us/step - loss: 0.9851\n",
            "Epoch 23/50\n",
            "4564/4564 [==============================] - 2s 418us/step - loss: 0.9860\n",
            "Epoch 24/50\n",
            "4564/4564 [==============================] - 2s 419us/step - loss: 0.9852\n",
            "Epoch 25/50\n",
            "4564/4564 [==============================] - 2s 415us/step - loss: 0.9849\n",
            "Epoch 26/50\n",
            "4564/4564 [==============================] - 2s 424us/step - loss: 0.9852\n",
            "Epoch 27/50\n",
            "4564/4564 [==============================] - 2s 415us/step - loss: 0.9844\n",
            "Epoch 28/50\n",
            "4564/4564 [==============================] - 2s 418us/step - loss: 0.9842\n",
            "Epoch 29/50\n",
            "4564/4564 [==============================] - 2s 416us/step - loss: 0.9842\n",
            "Epoch 30/50\n",
            "4564/4564 [==============================] - 2s 423us/step - loss: 0.9835\n",
            "Epoch 31/50\n",
            "4564/4564 [==============================] - 2s 418us/step - loss: 0.9832\n",
            "Epoch 32/50\n",
            "4564/4564 [==============================] - 2s 417us/step - loss: 0.9832\n",
            "Epoch 33/50\n",
            "4564/4564 [==============================] - 2s 421us/step - loss: 0.9824\n",
            "Epoch 34/50\n",
            "4564/4564 [==============================] - 2s 418us/step - loss: 0.9825\n",
            "Epoch 35/50\n",
            "4564/4564 [==============================] - 2s 414us/step - loss: 0.9827\n",
            "Epoch 36/50\n",
            "4564/4564 [==============================] - 2s 415us/step - loss: 0.9820\n",
            "Epoch 37/50\n",
            "4564/4564 [==============================] - 2s 419us/step - loss: 0.9815\n",
            "Epoch 38/50\n",
            "4564/4564 [==============================] - 2s 426us/step - loss: 0.9818\n",
            "Epoch 39/50\n",
            "4564/4564 [==============================] - 2s 419us/step - loss: 0.9798\n",
            "Epoch 40/50\n",
            "4564/4564 [==============================] - 2s 424us/step - loss: 0.9807\n",
            "Epoch 41/50\n",
            "4564/4564 [==============================] - 2s 417us/step - loss: 0.9792\n",
            "Epoch 42/50\n",
            "4564/4564 [==============================] - 2s 419us/step - loss: 0.9799\n",
            "Epoch 43/50\n",
            "4564/4564 [==============================] - 2s 420us/step - loss: 0.9794\n",
            "Epoch 44/50\n",
            "4564/4564 [==============================] - 2s 420us/step - loss: 0.9798\n",
            "Epoch 45/50\n",
            "4564/4564 [==============================] - 2s 419us/step - loss: 0.9794\n",
            "Epoch 46/50\n",
            "4564/4564 [==============================] - 2s 422us/step - loss: 0.9795\n",
            "Epoch 47/50\n",
            "4564/4564 [==============================] - 2s 420us/step - loss: 0.9787\n",
            "Epoch 48/50\n",
            "4564/4564 [==============================] - 2s 411us/step - loss: 0.9776\n",
            "Epoch 49/50\n",
            "4564/4564 [==============================] - 2s 415us/step - loss: 0.9787\n",
            "Epoch 50/50\n",
            "4564/4564 [==============================] - 2s 415us/step - loss: 0.9811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4869665908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "vvN99ugnKmaP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We now apply our predictive model on the test data (X_test) \n",
        "y_test_pred = nn.predict(X_test)\n",
        "\n",
        "#Accuracy score cannot be directly calculated given the output of the NN are not dummy variables, we must invert encode before\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYySaklkMWHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "81e38d9c-9c3c-4068-f267-aa9ae1f7473b"
      },
      "cell_type": "code",
      "source": [
        "# Invert encoding the targets\n",
        "inverted_y_test_pred = [ np.argmax(t) for t in y_test_pred ]\n",
        "inverted_y_test = [ np.argmax(t) for t in y_test ]\n",
        "\n",
        "#print(inverted_y_test_pred)\n",
        "#print(inverted_y_test)\n",
        "\n",
        "# We can now compute the accuracy score\n",
        "as_inv_nn = accuracy_score(inverted_y_test, inverted_y_test_pred)\n",
        "print(as_inv_nn)\n",
        "\n",
        "# Create the confusion matrix from the invert encoded targets.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm_nn = confusion_matrix(inverted_y_test, inverted_y_test_pred)\n",
        "print(cm_nn)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.46176470588235297\n",
            "[[  0   0  34]\n",
            " [  0   0 148]\n",
            " [  0   1 157]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}